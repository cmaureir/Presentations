\begin{frame}
    \frametitle{Introducción}
    \framesubtitle{}

\end{frame}


%Equation of State Calculations by Fast Computing Machines is an article published by Nicholas Metropolis, Arianna W. Rosenbluth, Marshall N. Rosenbluth, Augusta H. Teller, and Edward Teller in the Journal of Chemical Physics in 1953.[1] This paper proposed what became known as the Metropolis Monte Carlo algorithm, which forms the basis for Monte Carlo statistical mechanics simulations of atomic and molecular systems.[2] The attribution of the method to Metropolis is unfortunate, as "Metropolis played no role in its development other than providing computer time".[3] In fact, the theoretical work was done by Marshall N. Rosenbluth, who later gained renown as one of the greatest plasma physicists of the 20th century.
%Monte Carlo methods are a class of computational algorithms that rely on repeated random sampling to compute their results. In statistical mechanics applications prior to the introduction of the Metropolis algorithm, the method consisted of generating a large number of random configurations of the system, computing the properties of interest (such as energy or density) for each configuration, and then producing a weighted average where the weight of each configuration is its Boltzmann factor, exp(−E/kT), where E is the energy, T is the temperature, and k is Boltzmann's constant. The key contribution of the Metropolis paper was the idea that
%
%
%Instead of choosing configurations randomly, then weighting them with exp(−E/kT), we choose configurations with a probability exp(−E/kT) and weight them evenly.
%
%This change makes the sampling focus on the low-energy configurations, which contribute the most to the Boltzmann average, resulting in improved convergence. To choose configurations with a probability exp(−E/kT) that can be weighed evenly, the authors devised the following algorithm: 1) each configuration is generated by a random move on the previous configuration and the new energy is computed; 2) if the new energy is lower, the move is always accepted; otherwise the move is accepted with a probability of exp(−ΔE/kT). When a move is rejected, the last accepted configuration is counted again for the statistical averages and is used as a base for the next attempted move.
%
%The main topic of the article was the numerical calculation of the equation of state for a system of rigid spheres in two dimensions. Subsequent work generalized the method to three dimensions and to fluids using the Lennard-Jones potential. The simulations were done for a system of 224 particles; each simulation consisted of up to 48 cycles, where each cycle consisted of moving each particle once and took about three minutes of computer time using the MANIAC computer at Los Alamos National Lab.
%
%To minimize surface effects, the authors introduced the use of periodic boundary conditions. This means that the simulated system is treated as a unit cell in a lattice, and when a particle moves out of the cell, it automatically comes in through the other side.
%
%According to a perspective published nearly fifty years later by William L. Jorgensen, "Metropolis et al. introduced the samplic method and periodic boundary conditions that remain at the heart of Monte Carlo statistical mechanics simulations of fluids. This was one of the major contributions to theoretical chemistry of the twentieth century."[2] As of 2011, the article has been cited over 18,000 times.[4]
%
%In another perspective, it was said that although "the Metropolis algorithm began as a technique for attacking specific problems in numerical simulations of physical systems [...] later, the subject exploded as the scope of applications broadened in many surprising directions, including function minimization, computational geometry, and combinatorial counting. Today, topics related to the Metropolis algorithm constitute an entire field of computational science supported by a deep theory and having applications ranging from physical simulations to the foundations of computational complexity."[5]
%
%% http://en.wikipedia.org/wiki/Equation_of_State_Calculations_by_Fast_Computing_Machines
%
%
%Markov chain Monte Carlo (MCMC) methods (which include random walk Monte Carlo methods) are a class of algorithms for sampling from probability distributions based on constructing a Markov chain that has the desired distribution as its equilibrium distribution. The state of the chain after a large number of steps is then used as a sample of the desired distribution. The quality of the sample improves as a function of the number of steps.
%Usually it is not hard to construct a Markov chain with the desired properties. The more difficult problem is to determine how many steps are needed to converge to the stationary distribution within an acceptable error. A good chain will have rapid mixing—the stationary distribution is reached quickly starting from an arbitrary position—described further under Markov chain mixing time.
%Typical use of MCMC sampling can only approximate the target distribution, as there is always some residual effect of the starting position. More sophisticated MCMC-based algorithms such as coupling from the past can produce exact samples, at the cost of additional computation and an unbounded (though finite in expectation) running time.
%The most common application of these algorithms is numerically calculating multi-dimensional integrals. In these methods, an ensemble of "walkers" moves around randomly. At each point where the walker steps, the integrand value at that point is counted towards the integral. The walker then may make a number of tentative steps around the area, looking for a place with reasonably high contribution to the integral to move into next. Random walk methods are a kind of random simulation or Monte Carlo method. However, whereas the random samples of the integrand used in a conventional Monte Carlo integration are statistically independent, those used in MCMC are correlated. A Markov chain is constructed in such a way as to have the integrand as its equilibrium distribution. Surprisingly, this is often easy to do.
%Multi-dimensional integrals often arise in Bayesian statistics, computational physics, computational biology and computational linguistics, so Markov chain Monte Carlo methods are widely used in those fields. For example, see Gill[1] and Robert & Casella.[2]
%
%Random walk algorithms
%
%Many Markov chain Monte Carlo methods move around the equilibrium distribution in relatively small steps, with no tendency for the steps to proceed in the same direction. These methods are easy to implement and analyze, but unfortunately it can take a long time for the walker to explore all of the space. The walker will often double back and cover ground already covered. Here are some random walk MCMC methods:
%Metropolis–Hastings algorithm: Generates a random walk using a proposal density and a method for rejecting proposed moves.
%Gibbs sampling: Requires that all the conditional distributions of the target distribution can be sampled exactly. Popular partly because when this is so, the method does not require any 'tuning'.
%Slice sampling: Depends on the principle that one can sample from a distribution by sampling uniformly from the region under the plot of its density function. This method alternates uniform sampling in the vertical direction with uniform sampling from the horizontal 'slice' defined by the current vertical position.
%Multiple-try Metropolis: A variation of the Metropolis–Hastings algorithm that allows multiple trials at each point. This allows the algorithm to generally take larger steps at each iteration, which helps combat problems intrinsic to large dimensional problems.
%
%% http://en.wikipedia.org/wiki/Markov_chain_Monte_Carlo
